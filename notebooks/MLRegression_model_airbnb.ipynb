{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicción del precio de Airbnb Madrid España: Pre-procesamiento y Modelado "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info alert-info\"><b><h1>Objetivo</h1></b>\n",
    "    \n",
    "**Crear un modelo de regresión lineal con el dataset previamente analizado, asi como utilizar las métricas para interpretar los resultados.**\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción:  \n",
    "\n",
    "En el notebook anterior se realizó un análisis detallado de los precios de Airbnb en Madrid con R. Se llevaron a cabo los siguientes pasos: \n",
    "* Descripción de Datos.\n",
    "* Limpieza y Preparación de Datos.\n",
    "* Visualización de Datos. \n",
    "\n",
    "En este notebook, nos enfocaremos en aplicar técnicas de modelado y verificación del modelo para predecir los precios de los listados en Madrid. El objetivo final es desarrollar un modelo predictivo con regresión lineal, que pueda ayudar a sugerir precios para futuros listados de Airbnb en la ciudad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Descripción de Variables:  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: '/home/neivysg/keepcoding_glovo_bootcamp/Tech-Girls-Glovo/notebooks/variables.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Miriam\\anaconda3\\Lib\\site-packages\\IPython\\core\\display.py:1045\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1045\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m b2a_base64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Miriam\\anaconda3\\Lib\\site-packages\\IPython\\core\\formatters.py:974\u001b[0m, in \u001b[0;36mMimeBundleFormatter.__call__\u001b[1;34m(self, obj, include, exclude)\u001b[0m\n\u001b[0;32m    971\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    973\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 974\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m method(include\u001b[38;5;241m=\u001b[39minclude, exclude\u001b[38;5;241m=\u001b[39mexclude)\n\u001b[0;32m    975\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Miriam\\anaconda3\\Lib\\site-packages\\IPython\\core\\display.py:1035\u001b[0m, in \u001b[0;36mImage._repr_mimebundle_\u001b[1;34m(self, include, exclude)\u001b[0m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed:\n\u001b[0;32m   1034\u001b[0m     mimetype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mimetype\n\u001b[1;32m-> 1035\u001b[0m     data, metadata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_and_metadata(always_both\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m metadata:\n\u001b[0;32m   1037\u001b[0m         metadata \u001b[38;5;241m=\u001b[39m {mimetype: metadata}\n",
      "File \u001b[1;32mc:\\Users\\Miriam\\anaconda3\\Lib\\site-packages\\IPython\\core\\display.py:1047\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m b2a_base64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1047\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1048\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m md \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file or directory: '/home/neivysg/keepcoding_glovo_bootcamp/Tech-Girls-Glovo/notebooks/variables.png'"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file or directory: '/home/neivysg/keepcoding_glovo_bootcamp/Tech-Girls-Glovo/notebooks/variables.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Miriam\\anaconda3\\Lib\\site-packages\\IPython\\core\\display.py:1045\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1044\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1045\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m b2a_base64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mTypeError\u001b[0m: a bytes-like object is required, not 'str'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Miriam\\anaconda3\\Lib\\site-packages\\IPython\\core\\formatters.py:344\u001b[0m, in \u001b[0;36mBaseFormatter.__call__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    342\u001b[0m     method \u001b[38;5;241m=\u001b[39m get_real_method(obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_method)\n\u001b[0;32m    343\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 344\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m method()\n\u001b[0;32m    345\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Miriam\\anaconda3\\Lib\\site-packages\\IPython\\core\\display.py:1067\u001b[0m, in \u001b[0;36mImage._repr_png_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_repr_png_\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1066\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_FMT_PNG:\n\u001b[1;32m-> 1067\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_and_metadata()\n",
      "File \u001b[1;32mc:\\Users\\Miriam\\anaconda3\\Lib\\site-packages\\IPython\\core\\display.py:1047\u001b[0m, in \u001b[0;36mImage._data_and_metadata\u001b[1;34m(self, always_both)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     b64_data \u001b[38;5;241m=\u001b[39m b2a_base64(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata, newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mascii\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1046\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1047\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[0;32m   1048\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata)) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m   1049\u001b[0m md \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file or directory: '/home/neivysg/keepcoding_glovo_bootcamp/Tech-Girls-Glovo/notebooks/variables.png'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(\"/home/neivysg/keepcoding_glovo_bootcamp/Tech-Girls-Glovo/notebooks/variables.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Librerías a utilizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'joypy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjoypy\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mjoypy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m joyplot\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Importar el módulo para la separación en train y test\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'joypy'"
     ]
    }
   ],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import joypy\n",
    "from joypy import joyplot\n",
    "\n",
    "\n",
    "# Importar el módulo para la separación en train y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Importar librerías para el análisis estadístico\n",
    "from scipy import stats\n",
    "from scipy.stats import shapiro, ttest_ind, mannwhitneyu\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Importar los módulos para el preprocesado\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# Importar los módulos para la Regresión\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# Importar los módulos para los cálculos métricos\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "# Importar módulo para el pipeline\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/neivysg/keepcoding_glovo_bootcamp/Tech-Girls-Glovo/data/processed/processed-air-bnb-listings.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_airbnb_clean \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/home/neivysg/keepcoding_glovo_bootcamp/Tech-Girls-Glovo/data/processed/processed-air-bnb-listings.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      2\u001b[0m                               sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[0;32m      3\u001b[0m                               encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUTF-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Miriam\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:948\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    945\u001b[0m )\n\u001b[0;32m    946\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 948\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Miriam\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:611\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    608\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    610\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 611\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    613\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    614\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Miriam\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1448\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1448\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\Miriam\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1705\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1703\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1704\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1705\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1706\u001b[0m     f,\n\u001b[0;32m   1707\u001b[0m     mode,\n\u001b[0;32m   1708\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1709\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1710\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1711\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1712\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1713\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1714\u001b[0m )\n\u001b[0;32m   1715\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1716\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Miriam\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:863\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    859\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    860\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    862\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 863\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    864\u001b[0m             handle,\n\u001b[0;32m    865\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    866\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    867\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    868\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    869\u001b[0m         )\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    871\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    872\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/neivysg/keepcoding_glovo_bootcamp/Tech-Girls-Glovo/data/processed/processed-air-bnb-listings.csv'"
     ]
    }
   ],
   "source": [
    "df_airbnb_clean = pd.read_csv('/home/neivysg/keepcoding_glovo_bootcamp/Tech-Girls-Glovo/data/processed/processed-air-bnb-listings.csv', \n",
    "                              sep=';', \n",
    "                              encoding='UTF-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Análisis General"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1. Verificar nulos y NaM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2. Verificar datos duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb_clean[df_airbnb_clean.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "\n",
    "   *  Se puede observar que el dataset  tiene valores nulos o NaN en las columnas names y Date.last.review. \n",
    "   *  Se puede observar que el data set no tiene valores duplicados.   \n",
    "   * Se tienen 14 variables objetos y 6 integer.\n",
    "   * Basado en el Análisis Exploratorio previo (Cuaderno R) se tienen seleccionadas inicialmente para el modelo de predicción los siguientes atributos; sin embargo, previamente se realizará un análisis estadístico preliminar a la selección final o caso base:\n",
    "      - Atributo objetivo: Room.Price\n",
    "      - Numéricas: Minimum.nights, Number.of.reviews, Number.of.reviews.per.month, Latitude, Longitude.\n",
    "      - Categóricas: Neighbourhood, Room.type, Availability_Cat, Review_category, Review_Count_Category, Time_category.\n",
    "   * Se descartarán los atributos: Room.ID, Name, Host.ID, Date.last.review, Updated.Date, City, Country. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3. Eliminar atributos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo al analisis exploratorio previo, se eliminaran los atributos: Room.ID, Name, Host.ID, Date.last.review, Updated.Date, City, Country, como primer descarte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb_clean_vs_1 = df_airbnb_clean.drop(['Room.ID', 'Name', 'Host.ID', 'Date.last.review', 'Updated.Date', 'City', 'Country'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb_clean_vs_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4. Verificar tipos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar tipos de datos\n",
    "print(df_airbnb_clean_vs_1.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que Latitude, Longitude y Number.of.reviews.per.month están etiquetados como object, necesitamos convertir estas columnas a tipo numérico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir columnas a tipo numérico\n",
    "df_airbnb_clean_vs_1['Latitude'] = df_airbnb_clean_vs_1['Latitude'].str.replace(',', '.').astype(float)\n",
    "df_airbnb_clean_vs_1['Longitude'] = df_airbnb_clean_vs_1['Longitude'].str.replace(',', '.').astype(float)\n",
    "df_airbnb_clean_vs_1['Number.of.reviews.per.month'] = df_airbnb_clean_vs_1['Number.of.reviews.per.month'].str.replace(',', '.').astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb_clean_vs_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb_clean_vs_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.5. Descripción estadística y visualización global de las variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para determinar qué variables mantener para el modelo de predicción, necesitamos evaluar su correlación con el precio de la habitación (Room.Price) y considerar otras técnicas estadísticas. Los pasos serán:\n",
    "\n",
    "1. Sumario estadístico: Numéricas y categóricas.\n",
    "2. Evaluar la correlación: Ver la correlación de los atributos numéricos con Room.Price.\n",
    "3. Análisis de varianza: Evaluar variables categóricas con ANOVA.\n",
    "4. Aplicación de prueba de hipótesis para chequear la distribución normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.1 Sumario Estadístico:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variables Numéricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estadisticos_num(cont_data):\n",
    "    #Calcular estadísticas descriptivas, redondeamos y transponemos\n",
    "    estadisticos = cont_data.describe().round(3).T\n",
    "    #Añadir la mediana\n",
    "    estadisticos['median'] = cont_data.median().round(3)\n",
    "    #Reordenar para que la mediana esté al lado de la media\n",
    "    estadisticos = estadisticos.iloc[:,[0,1,8,2,3,4,5,6,7]]\n",
    "    #Pedir que nos devuelva los cálculos realizados\n",
    "    return(estadisticos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar la función a las variables numéricas\n",
    "Num_data = df_airbnb_clean_vs_1.select_dtypes(['float64', 'int64'])\n",
    "Num_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estadisticos_num(Num_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "\n",
    "* Room.Price: El precio medio de una habitación es de aproximadamente 164, pero la mediana es solo 60, lo que indica que hay algunos valores extremadamente altos (como el máximo de 9999) que están elevando la media. El 75% de las habitaciones cuestan 100 o menos.\n",
    "\n",
    "* Minimum.nights: La mayoría de las estancias requieren muy pocas noches, con una mediana de solo 2 noches. Sin embargo, el máximo es de 1125 noches, lo que indica que hay algunas que requieren estancias extremadamente largas.\n",
    "\n",
    "* Number.of.reviews: La mayoría de las habitaciones tienen pocas reseñas, con una mediana de solo 6 reseñas. Sin embargo, la media es de 34.875, lo que indica que hay algunas habitaciones con un número muy alto de reseñas.\n",
    "\n",
    "* Number.of.reviews.per.month: Similar a Number.of.reviews, la mayoría de las habitaciones tienen pocas reseñas por mes, pero hay algunas habitaciones con un número muy alto de reseñas por mes.\n",
    "\n",
    "* Rooms.rent.by.the.host: La mayoría de los anfitriones alquilan pocas habitaciones, con una mediana de solo 2 habitaciones. Sin embargo, el máximo es de 244, lo que indica que hay algunos anfitriones que alquilan un gran número de habitaciones.\n",
    "\n",
    "* Latitude y Longitude: Estas son las coordenadas geográficas de las habitaciones. No hay mucho que analizar aquí sin un contexto geográfico adicional.\n",
    "\n",
    "En general, parece que hay una gran variabilidad en los datos, con algunos valores extremos en varias columnas. Esto podría afectar a los modelos de machine learning si no se manejan adecuadamente. En el caso de la discretización es una buena estrategia para manejar variables numéricas con muchos valores únicos o con valores extremos. Al convertir \"Number.of.reviews\" y \"Number.of.reviews.per.month\" en categorías, reduces la complejidad de los datos y puedes ayudar al modelo a capturar patrones más generales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Variables Categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat = df_airbnb_clean_vs_1.select_dtypes('object')\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "\n",
    "* Neighbourhood: Hay 21255 observaciones no nulas, 127 barrios únicos, el barrio más común es \"Embajadores\", y \"Embajadores\" aparece 2559 veces.\n",
    "\n",
    "* Room.type: Hay 21255 observaciones no nulas, 4 tipos de habitaciones únicos, el tipo de habitación más común es \"Entire home/apt\", y \"Entire home/apt\" aparece 12704 veces.\n",
    "\n",
    "* Availability_Cat: Hay 21255 observaciones no nulas, 6 categorías de disponibilidad únicas, la categoría de disponibilidad más común es \"181 a 365 días\", y \"181 a 365 días\" aparece 8186 veces.\n",
    "\n",
    "* Review_category: Hay 21255 observaciones no nulas, 4 categorías de revisión únicas, la categoría de revisión más común es \"0-1/mes\", y \"0-1/mes\" aparece 8771 veces.\n",
    "\n",
    "* Review_Count_Category: Hay 21255 observaciones no nulas, 6 categorías de conteo de revisión únicas, la categoría de conteo de revisión más común es \"sin reseñas\", y \"sin reseñas\" aparece 5400 veces.\n",
    "\n",
    "* Time_category: Hay 21255 observaciones no nulas, 5 categorías de tiempo únicas, la categoría de tiempo más común es \"8 semanas - 6 meses\", y \"8 semanas - 6 meses\" aparece 7150 veces.\n",
    "\n",
    "* Estos resúmenes nos dan una idea de la distribución de las variables categóricas. Para usar estas variables en un modelo de machine learning, se tendrán que codificar en una forma que el modelo pueda entender, como one-hot encoding, ordinal encoding, target encoding, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.2 Evaluar la Correlación de atributos numéricos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El atributo Room.Price será el target o variable de predicción. Se crearán unos gráficos de dispersión de los atributos en función del atributo Room.Prices para ver su relación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Asignar el índice de la columna que queremos seleccionar\n",
    "col_idx = 0\n",
    "\n",
    "## Crear gráficos con cuatro columnas y tres filas\n",
    "fig, axes = plt.subplots(ncols=3, nrows=3, figsize=(30, 15))\n",
    "\n",
    "## Recorrer cada subplot y hacemos un scatterplot\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        if col_idx < len(Num_data.columns):\n",
    "            col = Num_data.columns[col_idx]\n",
    "            if np.issubdtype(Num_data[col].dtype, np.number):  # Comprueba si la columna es numerica\n",
    "                axes[i, j].plot(Num_data[col], Num_data['Room.Price'], 'o', color='tab:blue')\n",
    "                axes[i, j].set_xlabel(Num_data.columns[col_idx], fontsize=20)\n",
    "                axes[i, j].set_ylabel('Room.Price', fontsize=20)\n",
    "                axes[i, j].set_title('R: {:.4f}'.format(Num_data[['Room.Price', col]].corr().iloc[0, 1]), fontsize=20)\n",
    "                fig.suptitle('Scatterplot of all features', fontsize=30)\n",
    "            col_idx += 1\n",
    "        else:\n",
    "            axes[i, j].axis('off')  # Desactiva el eje si no hay más columnas disponibles\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.03, 1, 0.95])  # Ajusta el espacio entre subplots\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcular la correlación\n",
    "correlation_matrix = Num_data.corr()\n",
    "print(correlation_matrix['Room.Price'].sort_values(ascending=False))\n",
    "\n",
    "# Crear la máscara\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "\n",
    "# Visualizar la matriz de correlación\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', mask=mask)\n",
    "ax.set_title('Correlation Heatmap', fontdict={'fontsize':14}, pad=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.3 Análisis de Varianza (ANOVA) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Análisis de Varianza (ANOVA) para Variables Categóricas: \n",
    "Evaluemos las variables categóricas (Neighbourhood, Room.type, City, Country, Availability_Cat, Review_category, Review_Count_Category, Time_category) con ANOVA para ver si tienen una relación significativa con Room.Price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazar los puntos en los nombres de las columnas con guiones bajos\n",
    "df_airbnb_clean_vs_1.columns = df_airbnb_clean_vs_1.columns.str.replace('.', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizar ANOVA para cada variable categórica\n",
    "anova_results = {}\n",
    "\n",
    "for var in df_airbnb_clean_vs_1.columns:\n",
    "    if var != 'Room_Price':\n",
    "        model = ols(f'Room_Price ~ {var}', data=df_airbnb_clean_vs_1).fit()\n",
    "        anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "        anova_results[var] = anova_table\n",
    "\n",
    "# Mostrar resultados\n",
    "for var, anova_table in anova_results.items():\n",
    "    print(f\"ANOVA results for {var}:\")\n",
    "    print(anova_table)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observaciones:**\n",
    "* Room_type: Con un valor F de 68.94 y un valor p extremadamente pequeño (2.33e-44), esto indica que el tipo de habitación tiene un efecto significativo en el precio de la habitación.\n",
    "\n",
    "* Number_of_reviews: Con un valor F de 119.92 y un valor p extremadamente pequeño (7.82e-28), esto indica que el número de revisiones tiene un efecto significativo en el precio de la habitación.\n",
    "\n",
    "* Number_of_reviews_per_month: Con un valor F de 177.70 y un valor p extremadamente pequeño (2.24e-40), esto indica que el número de revisiones por mes tiene un efecto significativo en el precio de la habitación.\n",
    "\n",
    "* Rooms_rent_by_the_host: Con un valor F de 631.93 y un valor p extremadamente pequeño (1.93e-137), esto indica que el número de habitaciones alquiladas por el anfitrión tiene un efecto significativo en el precio de la habitación.\n",
    "\n",
    "* Latitude y Longitude: Ambas tienen valores F significativos y valores p muy pequeños, lo que indica que la ubicación geográfica de la habitación (latitud y longitud) tiene un efecto significativo en el precio de la habitación.\n",
    "\n",
    "* Availability_Cat, Review_category, Review_Count_Category, y Time_category: Todas estas variables tienen valores F significativos y valores p muy pequeños, lo que indica que tienen un efecto significativo en el precio de la habitación.\n",
    "\n",
    "En resumen, todas las variables, excepto Minimum_nights, parecen tener un efecto significativo en el precio de la habitación, según los resultados de ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.5.4 Aplicación de prueba de hipótesis para chequear la distribución normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_normal_distribution(data):\n",
    "    for i in data.columns:\n",
    "        shapiro_test = stats.shapiro(data[i])\n",
    "        print('La variable', i, 'tiene un p-value= ', shapiro_test.pvalue)\n",
    "        if shapiro_test.pvalue>0.05:\n",
    "            print('Se acepta la hipotesis nula, la muestra tiene una distribución normal (Probablemente Gaussiana).\\n')\n",
    "        else:\n",
    "            print('Se rechaza la hipotesis nula, la muestra no tiene una distribución normal (Probablemente no Gaussiana).\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_normal_distribution(Num_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Pre-Procesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez realizado el análisis general del dataset limpio y seleccionados los atributos para la predicción del precio, se aplicarán al preprocesamiento de los datos las siguientes normalizaciones: \n",
    "\n",
    "**Atributos Categóricos:**\n",
    " * Neighbourhood\n",
    " * Room.type\t\n",
    " * Availability_Cat\t\n",
    " * Review_category y Review_Count_Category: en cuanto a los atributos Number.of.reviews\" y \"Number.of.reviews.per.month\" se observó una gran variabilidad en sus datos, por lo cual fueron convertidas en categóricas en el análisis exploratorio en R. \n",
    "\n",
    "**Atributos Numéricos:** \n",
    "Dado que las variables numéricas independientes no tienen distribucción normal o gausiona se les aplicara normalización:\n",
    " * Outliers: De acuerdo al analisis exploratorio en R, se tienen los siguientes atributos con outliers: Minimum.nights, Rooms.rent.by.the.host, Latitude y Longitude por lo que se le aplicará **RobustScaler**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una copia del dataframe original con la eliminación de la columna 'Time_category'\n",
    "df_airbnb_transformed = df_airbnb_clean_vs_1.drop(['Number_of_reviews', 'Number_of_reviews_per_month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb_transformed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1. Transformaciones numéricas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Outliers\n",
    "columns_outliers =['Minimum_nights', 'Rooms_rent_by_the_host', 'Latitude', 'Longitude']\n",
    "Robust_scaler = preprocessing.RobustScaler().fit(df_airbnb_transformed[columns_outliers])\n",
    "df_airbnb_transformed[columns_outliers] = Robust_scaler.transform(df_airbnb_transformed[columns_outliers])\n",
    "\n",
    "#dataset normalizado\n",
    "df_airbnb_transformed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### gráfico para ver la mejora\n",
    "\n",
    "variables = ['Minimum_nights', 'Rooms_rent_by_the_host', 'Latitude', 'Longitude']\n",
    "\n",
    "fig, axs = plt.subplots(ncols=2, nrows=2, figsize=(8, 8))\n",
    "axs = axs.flatten()\n",
    "\n",
    "for index, variable in enumerate(variables):\n",
    "    sns.boxplot(y=variable, data=df_airbnb_transformed, ax=axs[index])\n",
    "\n",
    "plt.tight_layout(pad=0.4, w_pad=0.5, h_pad=5.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A pesar de las transformaciones, no mejoran significativamente los valores de los outliers, por lo que se puede plantear probar un modelo eliminando los outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2. Transformaciones Categóricas:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para la transformación de las variables categóricas, existen diferentes tecnicas, sin embargo las mas comunes son una técnica llamada codificación one-hot de sklearn y en Python, puedes usar la función get_dummies() de pandas para hacer esto. Para el proyecto se utilizará Sklearn OneHotEncoder con ColumnTransformer, es más robusto y flexible, especialmente si estás construyendo un pipeline de machine learning que incluye preprocesamiento y modelado. \n",
    "Puede manejar nuevas categorías en los datos de prueba que no estaban presentes en los datos de entrenamiento. Además, permite aplicar diferentes transformaciones a diferentes columnas, lo que es útil si también necesitas preprocesar variables numéricas de diferentes maneras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las columnas categóricas que quieres transformar\n",
    "categorical_features = ['Neighbourhood', 'Room_type', 'Availability_Cat', 'Review_category', 'Review_Count_Category', 'Time_category']\n",
    "\n",
    "# Crear el OneHotEncoder\n",
    "encoder = OneHotEncoder(drop='first')\n",
    "\n",
    "# Ajustar y transformar tus datos\n",
    "categorical_transformed = encoder.fit_transform(df_airbnb_transformed[categorical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a DataFrame\n",
    "categorical_transformed = pd.DataFrame(categorical_transformed.toarray(), columns=encoder.get_feature_names_out(categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminar las columnas categóricas originales de df_airbnb_transformed\n",
    "df_airbnb_transformed = df_airbnb_transformed.drop(columns=categorical_features)\n",
    "\n",
    "# Unir el DataFrame transformado con df_airbnb_transformed\n",
    "df_airbnb_transformed = pd.concat([df_airbnb_transformed, categorical_transformed], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb_transformed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb_transformed.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb_transformed.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Definir Objetivos y atributos independientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define la variable dependiente y las independientes\n",
    "x = df_airbnb_transformed.drop(columns = 'Room_Price', axis=1)\n",
    "y = df_airbnb_transformed['Room_Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Para realizar la división del Dataset: Training y Test (Entrenamineto y prueba), se utilizará 80% para el Train y 20% para el Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividir los datos de entrenamiento y test\n",
    "#random_state=4\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, random_state=42, train_size=0.8)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el proyecto de predicción de Precios del inmueble con el algortimo de regresión lineal en función de las características que se seleccionaron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Caso base: Regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Instanciar el modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciar\n",
    "rm = LinearRegression()\n",
    "\n",
    "#Entrenar\n",
    "rm.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Predecir el modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción del modelo con los datos de entrenamiento (train data)\n",
    "y_train_pred_rm = rm.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción del modelo con los datos de prueba (test data)\n",
    "y_pred_rm = rm.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion = pd.DataFrame(y_pred_rm, columns = ['PREDICCION'])\n",
    "prediccion.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Evaluar el modelo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar cada modelo se calculará:\n",
    "* El R2, que es una medida de la relación lineal entre X e Y, se interpreta como la proporción de la varianza en la variable dependiente que es predecible a partir de la variable independiente. \n",
    "* El MSE es una medida que indica qué tan cerca está la regresión de los puntos observados. Cuanto menor sea el MSE, mejor será el pronóstico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluacion(data, predicted): \n",
    "    \n",
    "    r2_square = metrics.r2_score(data, predicted)\n",
    "    mse = metrics.mean_squared_error(data, predicted)\n",
    "    errors = mean_absolute_error(data, predicted)\n",
    "    \n",
    "    print('R2 : ', r2_square)\n",
    "    print('MAE (Error Absoluto Medio) : ',  errors)\n",
    "    \n",
    "    return {'R2': r2_square, 'MAE': errors}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo con los datos de entrenamiento (train data)\n",
    "evaluacion(y_train, y_train_pred_rm )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo con los datos de prueba (test data)\n",
    "evaluacion(y_test, y_pred_rm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Caso: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciar\n",
    "rfr = RandomForestRegressor(max_depth= 25, max_features= 'sqrt', min_samples_leaf= 2, min_samples_split= 5, n_estimators= 100)\n",
    "\n",
    "#Entrenar\n",
    "rfr.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción del modelo con los datos de entrenamiento (train data)\n",
    "y_train_pred_rFr = rfr.predict(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción del modelo con los datos de prueba (test data)\n",
    "y_pred_rFr = rfr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_rfr = pd.DataFrame(y_pred_rFr, columns = ['PREDICCION'])\n",
    "prediccion_rfr .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo con los datos de entrenamiento (train data)\n",
    "evaluacion(y_train, y_train_pred_rFr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo con los datos de prueba (test data)\n",
    "evaluacion(y_test, y_pred_rFr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Caso XGBoost "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost es una biblioteca optimizada para implementaciones de boosting que es extremadamente eficiente y puede manejar valores atípicos de manera efectiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo con los hiperparámetros obtenidos\n",
    "xgbr = xgb.XGBRegressor(\n",
    "    colsample_bytree=0.9,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    min_child_weight=3,\n",
    "    n_estimators=200,\n",
    "    subsample=0.9,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "xgbr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir en el conjunto de entrenamiento y prueba\n",
    "y_train_pred_xgbr = xgbr.predict(x_train)\n",
    "y_test_pred_xgbr = xgbr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_xgbr = pd.DataFrame(y_test_pred_xgbr, columns = ['PREDICCION'])\n",
    "prediccion_xgbr .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo con los datos de entrenamiento (train data)\n",
    "evaluacion(y_train, y_train_pred_xgbr )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo con los datos de prueba (test data)\n",
    "evaluacion(y_test, y_test_pred_xgbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Caso: Descartar las variables Latitud y Longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define la variable dependiente y las independientes\n",
    "x1 = df_airbnb_transformed.drop(columns = ['Room_Price', 'Latitude', 'Longitude'], axis=1)\n",
    "y1 = df_airbnb_transformed['Room_Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividir los datos de entrenamiento y test\n",
    "#random_state=4\n",
    "x_train_1, x_test_1, y_train_1, y_test_1 = train_test_split(x1, y1, random_state=42, train_size=0.80)\n",
    "print(x_train_1.shape, x_test_1.shape, y_train_1.shape, y_test_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Random Forest:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciar\n",
    "rFr =RandomForestRegressor(max_depth= 25, max_features= 'sqrt', min_samples_leaf= 2, min_samples_split= 5, n_estimators= 100)\n",
    "\n",
    "#Entrenar\n",
    "rfr.fit(x_train_1,y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción del modelo con los datos de entrenamiento (train data)\n",
    "y_train_1_pred_rFr = rfr.predict(x_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción del modelo con los datos de prueba (test data)\n",
    "y_pred_rFr_1 = rfr.predict(x_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo con los datos de entrenamiento (train data)\n",
    "evaluacion(y_train, y_train_1_pred_rFr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo con los datos de prueba (test data)\n",
    "evaluacion(y_test_1, y_pred_rFr_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **XGBoost:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo con los hiperparámetros obtenidos\n",
    "xgbr = xgb.XGBRegressor(\n",
    "    colsample_bytree=0.9,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    min_child_weight=3,\n",
    "    n_estimators=200,\n",
    "    subsample=0.9,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "xgbr.fit(x_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir en el conjunto de entrenamiento y prueba\n",
    "y_train_1_pred_xgbr = xgbr.predict(x_train_1)\n",
    "y_test_1_pred_xgbr = xgbr.predict(x_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_xgbr_1 = pd.DataFrame(y_test_1_pred_xgbr, columns = ['PREDICCION'])\n",
    "prediccion_xgbr_1 .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo con los datos de entrenamiento (train data)\n",
    "evaluacion(y_train_1, y_train_1_pred_xgbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo con los datos de prueba (test data)\n",
    "evaluacion(y_test_1, y_test_1_pred_xgbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Caso: Descartar las variables Neiborhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb_clean_vs_1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb_no_neighb= df_airbnb_clean_vs_1.drop(['Neighbourhood', 'Number_of_reviews', 'Number_of_reviews_per_month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Transformacion Outliers\n",
    "columns_outliers =['Minimum_nights', 'Rooms_rent_by_the_host', 'Latitude', 'Longitude']\n",
    "Robust_scaler = preprocessing.RobustScaler().fit(df_airbnb_no_neighb[columns_outliers])\n",
    "df_airbnb_no_neighb[columns_outliers] = Robust_scaler.transform(df_airbnb_no_neighb[columns_outliers])\n",
    "\n",
    "#dataset normalizado\n",
    "df_airbnb_no_neighb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las columnas categóricas que quieres transformar\n",
    "categorical_features = ['Room_type', 'Availability_Cat', 'Review_category', 'Review_Count_Category', 'Time_category']\n",
    "\n",
    "# Crear el OneHotEncoder\n",
    "encoder = OneHotEncoder(drop='first')\n",
    "\n",
    "# Ajustar y transformar tus datos\n",
    "categorical_transformed = encoder.fit_transform(df_airbnb_no_neighb[categorical_features])\n",
    "\n",
    "# Convertir a DataFrame\n",
    "categorical_transformed = pd.DataFrame(categorical_transformed.toarray(), columns=encoder.get_feature_names_out(categorical_features))\n",
    "# Eliminar las columnas categóricas originales de df_airbnb_transformed\n",
    "df_airbnb_no_neighb = df_airbnb_no_neighb.drop(columns=categorical_features)\n",
    "\n",
    "# Unir el DataFrame transformado con df_airbnb_transformed\n",
    "df_airbnb_no_neighb = pd.concat([df_airbnb_no_neighb, categorical_transformed], axis=1)\n",
    "\n",
    "df_airbnb_no_neighb.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define la variable dependiente y las independientes\n",
    "x3 = df_airbnb_no_neighb.drop(columns = 'Room_Price', axis=1)\n",
    "y3 = df_airbnb_no_neighb['Room_Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividir los datos de entrenamiento y test\n",
    "#random_state=4\n",
    "x_train_3, x_test_3, y_train_3, y_test_3 = train_test_split(x3, y3, random_state=42, train_size=0.80)\n",
    "print(x_train_3.shape, x_test_3.shape, y_train_3.shape, y_test_3.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Random Forest:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciar\n",
    "rfr = RandomForestRegressor(max_depth= 25, max_features= 'sqrt', min_samples_leaf= 2, min_samples_split= 5, n_estimators= 100)\n",
    "\n",
    "#Entrenar\n",
    "rfr.fit(x_train_3,y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción del modelo con los datos de entrenamiento (train data)\n",
    "y_train_3_pred_rFr_3 = rfr.predict(x_train_3)\n",
    "\n",
    "# Predicción del modelo con los datos de prueba (test data)\n",
    "y_pred_rFr_3 = rfr.predict(x_test_3)\n",
    "\n",
    "prediccion_rfr_3 = pd.DataFrame(y_pred_rFr_3, columns = ['PREDICCION'])\n",
    "prediccion_rfr_3 .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo con los datos de entrenamiento (train data)\n",
    "evaluacion(y_train_3, y_train_3_pred_rFr_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo con los datos de prueba (test data)\n",
    "evaluacion(y_test_3, y_pred_rFr_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **XG Boost:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo con los hiperparámetros obtenidos\n",
    "xgbr = xgb.XGBRegressor(\n",
    "    colsample_bytree=0.9,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    min_child_weight=3,\n",
    "    n_estimators=200,\n",
    "    subsample=0.9,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "xgbr.fit(x_train_3, y_train_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir en el conjunto de entrenamiento y prueba\n",
    "y_train_3_pred_xgbr = xgbr.predict(x_train_3)\n",
    "y_test_pred_3_xgbr = xgbr.predict(x_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_xgbr_3 = pd.DataFrame(y_test_pred_3_xgbr, columns = ['PREDICCION'])\n",
    "prediccion_xgbr_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo con los datos de entrenamiento (train data)\n",
    "evaluacion(y_train_3, y_train_3_pred_xgbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo con los datos de prueba (test data)\n",
    "evaluacion(y_test_3, y_test_pred_3_xgbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.6. Caso Eliminar los outliers, previo las transformaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Eliminar los outliers del dataset original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código para eliminar outliers Nª1\n",
    "numeric_cols = df_airbnb_clean_vs_1.select_dtypes(include=[np.number]).columns\n",
    "Q1 = df_airbnb_clean_vs_1[numeric_cols].quantile(0.25)\n",
    "Q3 = df_airbnb_clean_vs_1[numeric_cols].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "df_airbnb_clean_no_outliers = df_airbnb_clean_vs_1[~((df_airbnb_clean_vs_1[numeric_cols] < (Q1 - 1.5 * IQR)) | (df_airbnb_clean_vs_1[numeric_cols] > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# % de outliers\n",
    "for k, v in df_airbnb_clean_no_outliers[numeric_cols].items():\n",
    "    q1 = v.quantile(0.25)\n",
    "    q3 = v.quantile(0.75)\n",
    "    irq = q3 - q1\n",
    "    v_col = v[(v <= q1 - 1.5 * irq) | (v >= q3 + 1.5 * irq)]\n",
    "    perc = np.shape(v_col)[0] * 100.0 / np.shape(df_airbnb_clean_no_outliers)[0]\n",
    "    print(\"Column %s outliers = %.2f%%\" % (k, perc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir el tamaño de la figura\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "# Calcular el número de filas y columnas necesarias para acomodar todos los subplots\n",
    "num_plots = len(numeric_cols)\n",
    "num_cols = int(np.ceil(np.sqrt(num_plots)))\n",
    "num_rows = int(np.ceil(num_plots / num_cols))\n",
    "\n",
    "# Crear un boxplot para cada columna numérica\n",
    "for i, col in enumerate(numeric_cols):\n",
    "    plt.subplot(num_rows, num_cols, i+1)\n",
    "    sns.boxplot(df_airbnb_clean_vs_1[col])\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observacion**\n",
    "A pesar de eliminar outliers, se continúa observando un % mínimo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb_clean_no_outliers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb_clean_no_outliers.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb_clean_no_outliers.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Transformación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una copia del dataframe original con la eliminación de la columna 'Time_category'\n",
    "df_airbnb_transf_no_outliers = df_airbnb_clean_no_outliers.drop(['Number_of_reviews', 'Number_of_reviews_per_month'], axis=1)\n",
    "\n",
    "df_airbnb_transf_no_outliers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power Transformer\n",
    "numeric_cols = list(df_airbnb_transf_no_outliers._get_numeric_data().columns)\n",
    "pt = PowerTransformer(method=\"yeo-johnson\")\n",
    "df_airbnb_transf_no_outliers[numeric_cols] = pt.fit_transform(df_airbnb_transf_no_outliers[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb_transf_no_outliers.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir las columnas categóricas que quieres transformar\n",
    "categorical_features = ['Room_type', 'Availability_Cat', 'Review_category', 'Review_Count_Category', 'Time_category', 'Neighbourhood']\n",
    "\n",
    "# Crear el OneHotEncoder\n",
    "encoder = OneHotEncoder(drop='first')\n",
    "\n",
    "# Ajustar y transformar tus datos\n",
    "categorical_transformed = encoder.fit_transform(df_airbnb_transf_no_outliers[categorical_features])\n",
    "\n",
    "# Convertir a DataFrame\n",
    "categorical_transformed = pd.DataFrame(categorical_transformed.toarray(), \n",
    "                                       columns=encoder.get_feature_names_out(categorical_features), \n",
    "                                       index=df_airbnb_transf_no_outliers.index)  # Mantén el mismo índice\n",
    "\n",
    "# Eliminar las columnas categóricas originales de df_airbnb_transformed\n",
    "df_airbnb_transf_no_outliers = df_airbnb_transf_no_outliers.drop(columns=categorical_features)\n",
    "\n",
    "# Unir el DataFrame transformado con df_airbnb_transformed\n",
    "df_airbnb_transf_no_outliers = pd.concat([df_airbnb_transf_no_outliers, categorical_transformed], axis=1)\n",
    "\n",
    "df_airbnb_transf_no_outliers.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_airbnb_transf_no_outliers.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Variable objetivo (target) y atributos (feature)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se define la variable dependiente y las independientes\n",
    "x4 = df_airbnb_transf_no_outliers.drop(columns = 'Room_Price', axis=1)\n",
    "y4 = df_airbnb_transf_no_outliers['Room_Price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividir los datos de entrenamiento y test\n",
    "#random_state=4\n",
    "x_train_4, x_test_4, y_train_4, y_test_4 = train_test_split(x4, y4, random_state=42, train_size=0.8)\n",
    "print(x_train_4.shape, x_test_4.shape, y_train_4.shape, y_test_4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciar\n",
    "rfr = RandomForestRegressor(max_depth= 25, max_features= 'sqrt', min_samples_leaf= 2, min_samples_split= 5, n_estimators= 100)\n",
    "\n",
    "#Entrenar\n",
    "rfr.fit(x_train_4,y_train_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción del modelo con los datos de entrenamiento (train data)\n",
    "y_train_4_pred_rFr_4 = rfr.predict(x_train_4)\n",
    "\n",
    "# Predicción del modelo con los datos de prueba (test data)\n",
    "y_pred_rFr_4 = rfr.predict(x_test_4)\n",
    "\n",
    "prediccion_rfr_4 = pd.DataFrame(y_pred_rFr_4, columns = ['PREDICCION'])\n",
    "prediccion_rfr_4 .head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo con los datos de entrenamiento (train data)\n",
    "evaluacion(y_train_4, y_train_4_pred_rFr_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo con los datos de prueba (test data)\n",
    "evaluacion(y_test_4, y_pred_rFr_4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = []\n",
    "\n",
    "# Caso base: Regresión Lineal\n",
    "resultados.append({'Caso': 'Regresión Lineal', **evaluacion(y_test, y_pred_rm)})\n",
    "\n",
    "# Caso 2: Random Forest\n",
    "resultados.append({'Caso': 'Random Forest', **evaluacion(y_test, y_pred_rFr)})\n",
    "\n",
    "# Caso 3: XGBoost \n",
    "resultados.append({'Caso': 'XGBoost', **evaluacion(y_test, y_test_pred_xgbr)})\n",
    "\n",
    "# Caso 4.1: Random Forest sin coordenadas\n",
    "# Supongamos que `y_pred_rf_sin_coordenadas` son las predicciones del modelo Random Forest sin coordenadas\n",
    "resultados.append({'Caso': 'RF sin coordenadas', **evaluacion(y_test_1, y_pred_rFr_1)})\n",
    "\n",
    "# Caso 4.2: XG Boost sin coordenadas\n",
    "# Supongamos que `y_pred_rf_sin_coordenadas` son las predicciones del modelo Random Forest sin coordenadas\n",
    "resultados.append({'Caso': 'XG Boost sin coordenadas', **evaluacion(y_test_1, y_test_1_pred_xgbr)})\n",
    "\n",
    "# Caso 5.1: Random Forest sin Barrios\n",
    "# Supongamos que `y_pred_rf_sin_barrios` son las predicciones del modelo Random Forest sin barrios\n",
    "resultados.append({'Caso': 'RF sin Barrios', **evaluacion(y_test_3, y_pred_rFr_3)})\n",
    "\n",
    "# Caso 5.2:  XG Boost sin Barrios\n",
    "# Supongamos que `y_pred_rf_sin_barrios` son las predicciones del modelo Random Forest sin barrios\n",
    "resultados.append({'Caso': 'XG Boost sin Barrios', **evaluacion(y_test_3,  y_test_pred_3_xgbr)})\n",
    "\n",
    "# Caso 6: Random Forest sin outliers\n",
    "# Supongamos que `y_pred_rf_sin_outliers` son las predicciones del modelo Random Forest sin outliers\n",
    "resultados.append({'Caso': 'RF sin outliers', **evaluacion(y_test_4, y_pred_rFr_4)})\n",
    "\n",
    "# Convertir la lista en un DataFrame\n",
    "df_resultados = pd.DataFrame(resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resultados.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se crea una copia del dataframe original con la eliminación de las columnas 'Number_of_reviews' y 'Number_of_reviews_per_month'\n",
    "df_airbnb_transformed = df_airbnb_clean_vs_1.drop(['Number_of_reviews', 'Number_of_reviews_per_month'], axis=1)\n",
    "\n",
    "# Definir las columnas numéricas y categóricas\n",
    "numeric_features = ['Minimum_nights', 'Rooms_rent_by_the_host', 'Latitude', 'Longitude']\n",
    "categorical_features = ['Neighbourhood', 'Room_type', 'Availability_Cat', 'Review_category', 'Review_Count_Category', 'Time_category']\n",
    "\n",
    "# Definir los transformadores para las columnas numéricas y categóricas\n",
    "numeric_transformer = RobustScaler()\n",
    "categorical_transformer = OneHotEncoder(drop='first')\n",
    "\n",
    "# Crear el modelo con los hiperparámetros obtenidos\n",
    "xgbr = xgb.XGBRegressor(\n",
    "    colsample_bytree=0.9,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    min_child_weight=3,\n",
    "    n_estimators=200,\n",
    "    subsample=0.9,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Combinar los transformadores en un preprocesador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)])\n",
    "\n",
    "# Definir la pipeline\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', xgbr)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X = df_airbnb_transformed.drop('Room_Price', axis=1)\n",
    "y = df_airbnb_transformed['Room_Price']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Entrenar la pipeline con los datos de entrenamiento\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Usar la pipeline para hacer predicciones con los datos de prueba\n",
    "predictions = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supongamos que new_data es el nuevo DataFrame\n",
    "new_data = pd.DataFrame({\n",
    "    'Minimum_nights': [3],\n",
    "    'Rooms_rent_by_the_host': [13],\n",
    "    'Latitude': [40.40],\n",
    "    'Longitude': [-3.70175],\n",
    "    'Neighbourhood': ['Embajadores'],\n",
    "    'Room_type': ['Entire home/apt'],\n",
    "    'Availability_Cat': ['Hasta 30 días'],\n",
    "    'Review_category': ['0-1/mes'],\n",
    "    'Review_Count_Category': ['11-50 reseñas'],\n",
    "    'Time_category': ['8 semanas - 6 meses']\n",
    "})\n",
    "\n",
    "# Usar la pipeline para hacer predicciones\n",
    "predictions = pipeline.predict(new_data)\n",
    "\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar la pipeline para hacer predicciones\n",
    "predictions = pipeline.predict(new_data)\n",
    "\n",
    "# Calcular el rango de precios basado en el MAE\n",
    "lower_bound = int(predictions[0] - 96.87)\n",
    "upper_bound = int(predictions[0] + 96.87)\n",
    "\n",
    "# Redondear el precio a dos decimales\n",
    "predicted_price = round(predictions[0], 2)\n",
    "\n",
    "print(f\"El precio predicho es aproximadamente {predicted_price}, con un rango de {lower_bound} a {upper_bound}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusiones y limitaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.1. **Conclusiones:**\n",
    "\n",
    "Basado en los resultados se concluye lo siguiente:\n",
    "\n",
    "* Aunque se normalizaron los outliers, no se observó una gran mejora en los datos. \n",
    "\n",
    "* Regresión Lineal: Este modelo tiene el rendimiento más bajo en términos de R^2 y el error absoluto medio (MAE) más alto. Esto sugiere que un modelo lineal puede no ser la mejor opción para este conjunto de datos, posiblemente porque la relación entre las características y la variable objetivo no es lineal.\n",
    "\n",
    "* Random Forest: Este modelo mejora significativamente el rendimiento en comparación con la regresión lineal. Sin embargo, hay variaciones en el rendimiento dependiendo de las características utilizadas.\n",
    "\n",
    "* Random Forest sin coordenadas: La eliminación de las coordenadas reduce ligeramente el rendimiento del modelo. Esto sugiere que las coordenadas son características importantes para el modelo.\n",
    "\n",
    "* Random Forest sin Barrios: Sorprendentemente, la eliminación de los barrios mejora el rendimiento del modelo. Esto podría indicar que la característica de los barrios puede estar introduciendo ruido en el modelo, o que otras características están capturando la misma información de una manera más efectiva.\n",
    "\n",
    "* Random Forest sin outliers: La eliminación de los outliers reduce el rendimiento del modelo, lo que sugiere que estos puntos de datos pueden contener información valiosa.\n",
    "\n",
    "* XGBoost: Este modelo tiene el rendimiento más alto en términos de R^2 y el MAE más bajo, lo que sugiere que puede ser la mejor opción para este conjunto de datos.\n",
    "\n",
    "* El modelo XGBoost parece ser el más preciso de los modelos que hemos probado, con un R^2 de 0.682136 y un MAE de 96.868375. Esto significa que el modelo puede explicar aproximadamente el 68.21% de la variación en los precios y que las predicciones del modelo se desvían del valor real en aproximadamente 96.87 unidades en promedio.\n",
    "\n",
    "* Se ha utilizado un modelo para predecir el precio de una nueva entrada de datos. El precio predicho es 165.0, con un rango de precios de 68 a 261 basado en el MAE de nuestro modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10.2 **Limitaciones**\n",
    "\n",
    "* Presencia de valores atípicos: los datos contienen valores atípicos, estos pueden afectar el rendimiento de nuestros modelos. Se podría considerar mejores técnicas para manejar estos valores atípicos, como truncarlos o utlizar otro tipo de transformación. \n",
    "\n",
    "* Aunque el modelo XGBoost tiene el mejor rendimiento de los modelos, todavía tiene un error considerable. El MAE de 96.868375 significa que las predicciones del modelo pueden desviarse bastante del valor real.\n",
    "\n",
    "* El rango de precios que hemos calculado se basa en el MAE de nuestro modelo. Sin embargo, este rango asume que el error es uniforme, lo que puede no ser el caso. Por ejemplo, el modelo puede tener un error mayor para precios más altos que para precios más bajos.\n",
    "\n",
    "* El rendimiento del modelo puede variar dependiendo de los datos de entrada. Por ejemplo, el modelo puede tener un rendimiento peor para ciertos barrios o tipos de habitaciones. Sería útil analizar el rendimiento del modelo para diferentes subconjuntos de los datos.\n",
    "\n",
    "* Finalmente, aunque el modelo puede hacer predicciones razonablemente precisas, todavía hay un 31.79% de variación en los precios que el modelo no puede explicar (1 - 0.682136). Esto significa que hay otros factores que afectan al precio que nuestro modelo no está considerando."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
